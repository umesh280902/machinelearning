{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0      1            5.1           3.5            1.4           0.2   \n",
      "1      2            4.9           3.0            1.4           0.2   \n",
      "2      3            4.7           3.2            1.3           0.2   \n",
      "3      4            4.6           3.1            1.5           0.2   \n",
      "4      5            5.0           3.6            1.4           0.2   \n",
      "..   ...            ...           ...            ...           ...   \n",
      "145  146            6.7           3.0            5.2           2.3   \n",
      "146  147            6.3           2.5            5.0           1.9   \n",
      "147  148            6.5           3.0            5.2           2.0   \n",
      "148  149            6.2           3.4            5.4           2.3   \n",
      "149  150            5.9           3.0            5.1           1.8   \n",
      "\n",
      "            Species  \n",
      "0       Iris-setosa  \n",
      "1       Iris-setosa  \n",
      "2       Iris-setosa  \n",
      "3       Iris-setosa  \n",
      "4       Iris-setosa  \n",
      "..              ...  \n",
      "145  Iris-virginica  \n",
      "146  Iris-virginica  \n",
      "147  Iris-virginica  \n",
      "148  Iris-virginica  \n",
      "149  Iris-virginica  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('./Iris/Iris.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0              5.1           3.5            1.4           0.2\n",
      "1              4.9           3.0            1.4           0.2\n",
      "2              4.7           3.2            1.3           0.2\n",
      "3              4.6           3.1            1.5           0.2\n",
      "4              5.0           3.6            1.4           0.2\n",
      "..             ...           ...            ...           ...\n",
      "145            6.7           3.0            5.2           2.3\n",
      "146            6.3           2.5            5.0           1.9\n",
      "147            6.5           3.0            5.2           2.0\n",
      "148            6.2           3.4            5.4           2.3\n",
      "149            5.9           3.0            5.1           1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "X=data[['SepalLengthCm'  ,'SepalWidthCm'  ,'PetalLengthCm' ,'PetalWidthCm']]\n",
    "print(X)\n",
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(data['Species'])\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "81             5.5           2.4            3.7           1.0\n",
      "133            6.3           2.8            5.1           1.5\n",
      "137            6.4           3.1            5.5           1.8\n",
      "75             6.6           3.0            4.4           1.4\n",
      "109            7.2           3.6            6.1           2.5\n",
      "..             ...           ...            ...           ...\n",
      "71             6.1           2.8            4.0           1.3\n",
      "106            4.9           2.5            4.5           1.7\n",
      "14             5.8           4.0            1.2           0.2\n",
      "92             5.8           2.6            4.0           1.2\n",
      "102            7.1           3.0            5.9           2.1\n",
      "\n",
      "[105 rows x 4 columns] [1 2 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1 2 0 1 2 0 2 2 1 1 2 1 0 1 2 0\n",
      " 0 1 1 0 2 0 0 1 1 2 1 2 2 1 0 0 2 2 0 0 0 1 2 0 2 2 0 1 1 2 1 2 0 2 1 2 1\n",
      " 1 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1 1 2 2 0 1 2 0 1 2]\n",
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "73             6.1           2.8            4.7           1.2\n",
      "18             5.7           3.8            1.7           0.3\n",
      "118            7.7           2.6            6.9           2.3\n",
      "78             6.0           2.9            4.5           1.5\n",
      "76             6.8           2.8            4.8           1.4\n",
      "31             5.4           3.4            1.5           0.4\n",
      "64             5.6           2.9            3.6           1.3\n",
      "141            6.9           3.1            5.1           2.3\n",
      "68             6.2           2.2            4.5           1.5\n",
      "82             5.8           2.7            3.9           1.2\n",
      "110            6.5           3.2            5.1           2.0\n",
      "12             4.8           3.0            1.4           0.1\n",
      "36             5.5           3.5            1.3           0.2\n",
      "9              4.9           3.1            1.5           0.1\n",
      "19             5.1           3.8            1.5           0.3\n",
      "56             6.3           3.3            4.7           1.6\n",
      "104            6.5           3.0            5.8           2.2\n",
      "69             5.6           2.5            3.9           1.1\n",
      "55             5.7           2.8            4.5           1.3\n",
      "132            6.4           2.8            5.6           2.2\n",
      "29             4.7           3.2            1.6           0.2\n",
      "127            6.1           3.0            4.9           1.8\n",
      "26             5.0           3.4            1.6           0.4\n",
      "128            6.4           2.8            5.6           2.1\n",
      "131            7.9           3.8            6.4           2.0\n",
      "145            6.7           3.0            5.2           2.3\n",
      "108            6.7           2.5            5.8           1.8\n",
      "143            6.8           3.2            5.9           2.3\n",
      "45             4.8           3.0            1.4           0.3\n",
      "30             4.8           3.1            1.6           0.2\n",
      "22             4.6           3.6            1.0           0.2\n",
      "15             5.7           4.4            1.5           0.4\n",
      "65             6.7           3.1            4.4           1.4\n",
      "11             4.8           3.4            1.6           0.2\n",
      "42             4.4           3.2            1.3           0.2\n",
      "146            6.3           2.5            5.0           1.9\n",
      "51             6.4           3.2            4.5           1.5\n",
      "27             5.2           3.5            1.5           0.2\n",
      "4              5.0           3.6            1.4           0.2\n",
      "32             5.2           4.1            1.5           0.1\n",
      "142            5.8           2.7            5.1           1.9\n",
      "85             6.0           3.4            4.5           1.6\n",
      "86             6.7           3.1            4.7           1.5\n",
      "16             5.4           3.9            1.3           0.4\n",
      "10             5.4           3.7            1.5           0.2 [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "print(X_train,Y_train)\n",
    "print(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "model=SVC(kernel='linear')\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Precision Score: 1.0\n",
      "Recall Score: 1.0\n",
      "Accuracy Score: 1.0\n",
      "F1-Measure: 1.0\n"
     ]
    }
   ],
   "source": [
    "#27,28,29,30\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Precision Score\n",
    "precision = precision_score(Y_test, y_pred, average='macro')  # Macro-averaging for multiclass\n",
    "print(\"Precision Score:\", precision)\n",
    "# Recall Score\n",
    "recall = recall_score(Y_test, y_pred, average='macro')\n",
    "print(\"Recall Score:\", recall)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# F1-Measure\n",
    "f1 = f1_score(Y_test, y_pred, average='macro')\n",
    "print(\"F1-Measure:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "rbfmodel=SVC(kernel='rbf')\n",
    "rbfmodel.fit(X_train,Y_train)\n",
    "y_pred_rbf=rbfmodel.predict(X_test)\n",
    "print(y_pred_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Precision Score: 1.0\n",
      "Recall Score: 1.0\n",
      "Accuracy Score: 1.0\n",
      "F1-Measure: 1.0\n"
     ]
    }
   ],
   "source": [
    "#31,32,33,34\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, y_pred_rbf)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Precision Score\n",
    "precision = precision_score(Y_test, y_pred_rbf, average='macro')  # Macro-averaging for multiclass\n",
    "print(\"Precision Score:\", precision)\n",
    "# Recall Score\n",
    "recall = recall_score(Y_test, y_pred_rbf, average='macro')\n",
    "print(\"Recall Score:\", recall)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(Y_test, y_pred_rbf)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# F1-Measure\n",
    "f1 = f1_score(Y_test, y_pred_rbf, average='macro')\n",
    "print(\"F1-Measure:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "Accuracy using GINI Index: 1.0\n"
     ]
    }
   ],
   "source": [
    "#35\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTreeModel=DecisionTreeClassifier(criterion='gini',max_depth=4,min_samples_split=2)\n",
    "decisionTreeModel.fit(X_train,Y_train)\n",
    "y_pred_decision_tree_gini=decisionTreeModel.predict(X_test)\n",
    "print(y_pred_decision_tree_gini)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred_decision_tree_gini)\n",
    "print(\"Accuracy using GINI Index:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Entropy : 1.0\n"
     ]
    }
   ],
   "source": [
    "#36\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTreeModelEntropy=DecisionTreeClassifier(criterion='entropy',max_depth=4,min_samples_split=2)\n",
    "decisionTreeModelEntropy.fit(X_train,Y_train)\n",
    "y_pred_decision_tree_entropy=decisionTreeModelEntropy.predict(X_test)\n",
    "# Evaluate Accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred_decision_tree_entropy)\n",
    "print(\"Accuracy using Entropy :\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Bagging Classifier): 1.0\n"
     ]
    }
   ],
   "source": [
    "#39\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy (Bagging Classifier):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest Classifier): 1.0\n"
     ]
    }
   ],
   "source": [
    "#40\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy (Random Forest Classifier):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Gradient Boosting Classifier): 1.0\n"
     ]
    }
   ],
   "source": [
    "#41\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy (Gradient Boosting Classifier):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (AdaBoost Classifier): 1.0\n"
     ]
    }
   ],
   "source": [
    "#42\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy (AdaBoost Classifier):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "Class Distribution:\n",
      "target\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Decision Tree Classifier Accuracy: 1.00\n",
      "Decision Tree Classifier Log Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Step 1: Understand the Dataset\n",
    "print(\"Iris Dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X = df[iris.feature_names]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Build a Decision Tree Classifier with Log Loss criterion\n",
    "dt_classifier = DecisionTreeClassifier(criterion='log_loss', max_depth=4, min_samples_split=2)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions and evaluate the model using Accuracy and Log Loss\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "y_pred_proba = dt_classifier.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nDecision Tree Classifier Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Decision Tree Classifier Log Loss: {log_loss_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classifier Accuracy (Binary Classification): 1.00\n",
      "Logistic Regression Classifier Log Loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize weights\n",
    "        self.weights = np.zeros(n_features)\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.num_iterations):\n",
    "            linear_model = np.dot(X, self.weights)\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "            # Update weights using gradient descent\n",
    "            gradient = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights)\n",
    "        y_predicted_prob = self.sigmoid(linear_model)\n",
    "        y_predicted_class = [1 if i > 0.5 else 0 for i in y_predicted_prob]\n",
    "        return np.array(y_predicted_class), y_predicted_prob\n",
    "\n",
    "# Load the Iris dataset again (or you can use the same data from above)\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert target to binary for logistic regression (e.g., class 0 vs others)\n",
    "y_binary = (y == 0).astype(int)  # Change this to classify between any two classes as needed\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Build a Logistic Regression Classifier from Scratch\n",
    "log_reg_classifier = LogisticRegression(learning_rate=0.01, num_iterations=10000)\n",
    "log_reg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Make predictions and evaluate the model using Accuracy and Log Loss\n",
    "y_pred_binary, y_pred_proba_binary = log_reg_classifier.predict(X_test)\n",
    "accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "# Calculate log loss manually for binary classification predictions\n",
    "epsilon = 1e-15  # To avoid log(0)\n",
    "y_pred_proba_binary = np.clip(y_pred_proba_binary, epsilon, 1 - epsilon)  # Clip predictions to avoid log(0)\n",
    "log_loss_value_binary = -np.mean(y_test * np.log(y_pred_proba_binary) + (1 - y_test) * np.log(1 - y_pred_proba_binary))\n",
    "\n",
    "print(f\"\\nLogistic Regression Classifier Accuracy (Binary Classification): {accuracy_binary:.2f}\")\n",
    "print(f\"Logistic Regression Classifier Log Loss: {log_loss_value_binary:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
